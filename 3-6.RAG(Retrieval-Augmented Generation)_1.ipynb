{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6014980f",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 0
        }
      },
      "source": [
        "# RAG (Retrieval-Augmented Generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e899e65",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 1
        }
      },
      "source": [
        "## 1. 왜 RAG가 중요한가?\n",
        "\n",
        "### 1.1 LLM의 한계\n",
        "\n",
        "최근 **대규모 언어 모델(LLM)** 은 자연어 처리, 텍스트 생성, 번역, 챗봇 등 다양한 분야에서 뛰어난 성능을 보여주고 있습니다.  \n",
        "그러나 LLM에도 몇 가지 **한계**가 존재합니다:\n",
        "\n",
        "- **환각(Hallucination)**  \n",
        "  모델이 실제 사실과 다르거나 잘못된 정보를 생성하는 현상  \n",
        "  - 예: 2025년 노벨 문학상 수상자는 …라는 질문에 실제 수상자와 다른 답변을 생성\n",
        "\n",
        "- **지식 업데이트 지연**  \n",
        "  LLM은 `사전 학습된 데이터에 기반`하므로, 최신 정보가 반영되지 않을 수 있음  \n",
        "  - 예: 최근 출시된 제품이나 논문 정보는 모델이 알지 못함\n",
        "\n",
        "- **희소 정보(Sparse Knowledge)에 대한 취약성**  \n",
        "  학습 데이터에서 드물게 등장하는 내용에 대해 정확한 답변을 생성하지 못함  \n",
        "  - 예: 거의 알려지지 않은 전자기기 기능, 일부 특수 분야의 세부 매뉴얼  \n",
        "  - 예: 대중적으로 잘 알려지지 않은 개인에 대한 질문\n",
        "\n",
        "- **투명성 부족**  \n",
        "  모델이 왜 특정 답변을 생성했는지 이해하거나 추적하기 어려움  \n",
        "  - 예: 단순히 출력 결과만 확인 가능, 내부 근거는 불명확\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e2df34",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 2
        }
      },
      "source": [
        "### 1.2 검색(Retrieval)과 생성(Generation) 결합 필요성\n",
        "\n",
        "LLM의 한계(최신 정보 부족, 희소 정보 취약, 환각 등)를 보완하기 위해 **검색(Retrieval)** 과 **생성(Generation)** 을 결합하는 방식이 등장했습니다.  \n",
        "\n",
        "이때 검색(Retrieval)은 크게 아래 두 가지로 나누어 이해할 수 있습니다.\n",
        "  1. **웹 검색(Web Retrieval)**\n",
        "  2. **문서 검색(Document Retrieval)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3b2c1f5",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 3
        }
      },
      "source": [
        "#### 1) 웹 검색(Web Retrieval)\n",
        "- 인터넷에서 **최신 정보**를 실시간으로 조회  \n",
        "- 최근 뉴스, 연구논문, 신제품, 변경된 규정 등 모델이 학습하지 못한 업데이트된 사실을 바로 반영 가능  \n",
        "  - 예: \"지금 대통령이 누구인가요?\" 질문에 정확한 답변 가능\n",
        "- LLM의 지식 업데이트 지연 문제 보완"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2a5590a",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 4
        }
      },
      "source": [
        "#### 2) 문서 검색(Document Retrieval)\n",
        "- 내부 DB, PDF, 매뉴얼, 논문, 회사 문서 등에서 **희소 정보(sparse knowledge)** 나 **전문 지식**을 찾아 제공  \n",
        "- 학습 데이터에 거의 등장하지 않는 정보도 정확하게 제공  \n",
        "  - 예: 특정 기업 내부 규정, 특수 장비 사용 설명서, 비공개 연구 자료 등  \n",
        "- LLM의 특수·희소 정보 취약 문제 보완"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef4898b6",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 5
        }
      },
      "source": [
        "#### 3) 생성(Generation)\n",
        "- **검색된 문서·웹 정보**를 기반으로 자연스럽고 일관된 답변을 생성  \n",
        "- 단순히 검색 결과를 나열하는 것이 아니라 **요약·통합·맥락 반영**까지 수행\n",
        "\n",
        "\n",
        "#### 결론\n",
        "> **웹 검색 → 최신 정보 보완**  \n",
        "> **문서 검색 → 희소·전문 지식 보완**  \n",
        "> **생성 → 자연스럽게 정리된 답변 제공**\n",
        "\n",
        "이렇게 검색과 생성을 결합한 구조가 바로  **RAG: Retrieval-Augmented Generation**이며  \n",
        "LLM의 현실적 한계를 극복하는 핵심 기술로 자리 잡고 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2203070",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 6
        }
      },
      "source": [
        "#### 예시 및 정리\n",
        "\n",
        "예를 들어, **자동차 제조 공장**에서 설비 위치를 파악하고 싶다고 가정해봅시다.\n",
        "\n",
        "- 질문: \"C공장 3라인의 용접 로봇 R-12 위치가 어디인가요?\"  \n",
        "- 단순 LLM(예: ChatGPT)만으로는 공장 내부 설비 위치와 같은 세부 정보는 알 수 없습니다.  \n",
        "- **RAG 접근**:  \n",
        "  1. **검색(Retrieval)** 단계에서 최신 공장 설계도, 설비 배치 문서, 유지보수 기록 등을 찾아 관련 정보를 확보합니다.  \n",
        "  2. **생성(Generation)** 단계에서 검색된 설비 배치 정보를 바탕으로, \"C공장 3라인의 용접 로봇 R-12는 조립 구역 중앙, 검사 라인 옆에 위치해 있습니다.\"처럼 자연스럽게 정리된 답변을 제공합니다.  \n",
        "\n",
        "이 방식은 단순히 문서를 보여주는 것이 아니라, 사용자가 실제로 필요로 하는 정보를 맥락에 맞게 **정리·통합**해서 전달할 수 있다는 장점이 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c88bd169",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 7
        }
      },
      "source": [
        "### 1.3 RAG 구성 요소\n",
        "\n",
        "RAG(Retrieval-Augmented Generation)는 기본적으로 세 가지 핵심 요소로 구성됩니다:\n",
        "\n",
        "- **Retriever(검색기)**  \n",
        "  질문과 관련된 문서나 정보를 실시간으로 검색\n",
        "- **Generator(생성기)**  \n",
        "  검색된 정보를 바탕으로 자연스럽게 답변 생성\n",
        "- **Augmentation 방법**  \n",
        "  검색 결과를 프롬프트에 결합하여 생성 모델이 활용할 수 있도록 통합\n",
        "\n",
        "💡 직관적 비유  \n",
        "- 기존 LLM: 머릿속 지식만으로 답변하는 사람  \n",
        "- RAG: 도서관에서 자료를 찾아 확인하고 답변하는 사람"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a2c875",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 8
        }
      },
      "source": [
        "#### RAG 구조 도식\n",
        "\n",
        "<img src=\"image/rag_example.png\" width=\"500\"> \n",
        "  \n",
        "이미지 출처 : https://valueminer.eu/retrieval-augmented-generation-rag/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aca3f73",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 9
        }
      },
      "source": [
        "### 1.4 RAG의 핵심 요약 및 산업적 필요성\n",
        "\n",
        "RAG는 **검색(사실 확보) + 생성(자연스러운 답변)** 의 조합을 통해 LLM의 구조적 한계(환각, 최신 정보 부재, 희소 정보 취약)를 보완하고,  \n",
        "산업 현장에서 요구하는 **정확성·근거·최신성**을 충족하는 핵심 기술입니다.\n",
        "\n",
        "특히 다음과 같은 이유로 기업 실무 도입 시 필수적인 기술로 자리 잡고 있습니다.\n",
        "\n",
        "- **기업 고유 지식(Internal Knowledge)의 안전한 활용**  \n",
        "  모델이 학습하지 못한 사내 비공개 데이터(기술 매뉴얼, 고객 DB, 사규 등)를 외부 유출 없이 실시간으로 참조하여 답변을 생성할 수 있음\n",
        "\n",
        "- **실시간(Real-time) 정보 의존 서비스 대응**  \n",
        "  금융, 물류, 공공 행정 등 매일 변동되는 정책·재고·가격 정보를 모델 재학습 없이 즉각적으로 반영하여 서비스 유지가 가능함\n",
        "\n",
        "- **고위험(High-Stakes) 산업군에서의 신뢰도 확보**  \n",
        "  제조, 의료, 법률 등 부정확한 답변이 금전적 손실이나 사고로 직결되는 분야에서, 명확한 근거(Source)를 기반으로 답변하여 환각 현상을 최소화함"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39704f33",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 10
        }
      },
      "source": [
        "#### 보안 때문에 오픈소스 모델 + RAG 조합이 더욱 확산되는 이유\n",
        "\n",
        "많은 기업들은 다음 이유로 ChatGPT 같은 상용 모델을 그대로 쓰기 어렵습니다:\n",
        "\n",
        "- 민감한 정보를 외부 서버로 보내기 어려움 (보안/규정)  \n",
        "- 클라우드 기반 모델의 개인정보 규제가 강화  \n",
        "- 데이터가 외부로 유출될 가능성을 원천 차단하고 싶음  \n",
        "\n",
        "그래서 기업들은 성능은 다소 낮지만, **로컬 또는 사내 서버에서 직접 실행 가능한 오픈소스 모델(Llama, Gemma 등)** 을 선호하는데,  \n",
        "이때 부족한 성능을 보완하기 위한 핵심 전략이 바로 **RAG** 입니다.\n",
        "\n",
        "> 오픈소스 모델 + 사내 문서 RAG => **보안 유지 + 높은 정확도 + 최신 정보 반영** 을 동시에 만족시키는 사실상 업계 표준 조합\n",
        "\n",
        "\n",
        "#### 결론\n",
        "\n",
        "RAG는 단순한 LLM 보조 기술이 아니라 **기업 환경에서 신뢰도·보안·업무 정확성을 보장하기 위한 필수 기술 스택**입니다.  \n",
        "고성능 상용 모델은 물론, 사내에서 운영하는 오픈소스 모델에서도  \n",
        "RAG가 결합될 때 비로소 실무에서 사용할 수 있는 수준의 품질을 확보할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cef7a2ab",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 11
        }
      },
      "source": [
        "## 2. RAG 기본 이해\n",
        "\n",
        "### 2.1 정의와 개념\n",
        "\n",
        "**RAG (Retrieval-Augmented Generation)** 은 LLM의 답변 품질을 높이기 위해  \n",
        "모델 외부에서 필요한 정보를 찾아(Look-up) 이를 바탕으로 생성(Generate)하는 기술입니다.\n",
        "\n",
        "- **핵심 개념**  \n",
        "  - LLM이 가진 사전 지식만으로 답변하지 않고  \n",
        "  - **검색을 통해 확보한 최신·정확한 정보를 함께 참조하여 답변을 생성하는 구조**\n",
        "\n",
        "- **해결하는 문제**  \n",
        "  - 환각(Hallucination) 완화  \n",
        "  - 최신 정보 반영  \n",
        "  - 답변 출처 및 근거 제시 → 투명성 확보\n",
        "\n",
        "- **적용 분야**  \n",
        "  - 고객지원 챗봇, 기술문서 Q&A  \n",
        "  - 사내 문서 기반 정보 검색 시스템  \n",
        "  - 법률/의료/제조 등 근거 기반 응답이 필요한 영역  \n",
        "  - 실시간 정보 기반 보고서·데이터 분석\n",
        "\n",
        "> 요약: RAG는 검색으로 사실 확보 + 생성으로 답변 구성이라는 두 단계를 결합해  \n",
        "> LLM의 한계를 보완하고 **정확성·신뢰성·업무 적용성**을 강화하는 기술입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8961d425",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 12
        }
      },
      "source": [
        "### 2.2 핵심 구성 요소\n",
        "\n",
        "RAG는 크게 세 가지 요소로 구성됩니다.\n",
        "\n",
        "<img src=\"image/RAG.png\" width=\"450\">\n",
        "\n",
        "1. **Retriever (검색기)**  \n",
        "   - 사용자의 질문과 의미적으로 가까운 문서·문장·데이터를 검색  \n",
        "   - 이때 **Embedding + Vector DB(FAISS, Chroma 등)** 를 활용하여 의미 기반 검색을 수행  \n",
        "   - 검색 품질이 최종 답변의 정확도에 직접적인 영향\n",
        "2. **Augmentation Methods (증강 방법)**  \n",
        "   - 검색된 문서를 LLM 입력(prompt)과 결합하는 방식  \n",
        "   - 단순 삽입, 우선순위 정렬 등 다양한 방식 존재\n",
        "\n",
        "3. **Generator (생성기)**  \n",
        "   - 검색된 문서를 바탕으로 자연스럽고 일관된 텍스트 생성  \n",
        "   - GPT, Llama 등 LLM이 Generator 역할을 수행  \n",
        "   - 단순 요약이 아니라 **문서 통합·정리·맥락 반영**까지 수행\n",
        "\n",
        "\n",
        "> Retriever는 ‘어떤 문서를 가져올 것인가’,  \n",
        "> Generator는 ‘가져온 문서로 어떤 답변을 만들 것인가’를 담당합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c008d731",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 13
        }
      },
      "source": [
        "### 2.3 벡터 임베딩과 의미 기반 검색의 원리\n",
        "\n",
        "RAG에서 검색(Retrieval)은 단순한 키워드 검색이 아니라, **텍스트의 의미(Semantics)** 를 기반으로 가장 관련성 높은 문서를 찾아오는 과정입니다.\n",
        "\n",
        "이를 가능하게 하는 핵심 기술이 바로 **벡터 임베딩(Vector Embedding)** 과 **벡터 데이터베이스(Vector Database)** 입니다.\n",
        "\n",
        "LLM 기반 검색 시스템이 어떻게 문서를 의미적으로 찾는지 이해하려면 다음 개념들을 알아야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ff1cdd",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 14
        }
      },
      "source": [
        "#### 1) 전통적 검색(RDBMS)의 한계\n",
        "\n",
        "<img src=\"image/RDBMS.png\" width=\"600\">  \n",
        "\n",
        "이미지 출처 : https://www.nilebits.com/blog/2023/03/key-differences-between-oracle-sql-server-mysql-and-postgresql/\n",
        "\n",
        "전통적 DB는 데이터를 **표 형태(행·열)** 로 저장하고,정확한 값 매칭 기반으로 검색합니다.\n",
        "\n",
        "예:\n",
        "- \"강아지\" != \"개\" → 단어가 다르면 다른 데이터\n",
        "- \"노트북이 꺼진다\" vs \"컴퓨터가 종료됩니다\" → 단어로 보면 유사성 없음\n",
        "\n",
        "➡ **의미적 연관성 파악 불가**  \n",
        "➡ 비정형 데이터(텍스트·이미지) 검색에 부적합\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816e8694",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 15
        }
      },
      "source": [
        "#### 2) 벡터 임베딩과 벡터 데이터베이스(Vector DB)\n",
        "\n",
        "벡터 임베딩은 텍스트·이미지·오디오 등을 **수백~수천 차원의 숫자 벡터로 변환하는 기술**입니다.  \n",
        "이 벡터는 단순한 숫자 배열이 아니라 **데이터의 의미적 특징을 표현한 방향 벡터**이며,  \n",
        "두 벡터의 유사성은 주로 다음과 같은 방식으로 계산됩니다:\n",
        "\n",
        "- **Cosine Similarity**: 두 벡터의 방향 유사도  \n",
        "- **Euclidean Distance(L2)**: 벡터 간 거리\n",
        "\n",
        "예시:\n",
        "\n",
        "\"고양이가 물을 마신다\" → [0.12, 0.03, ..., 0.76]  \n",
        "\"강아지가 물을 마신다\" → [0.15, 0.01, ..., 0.70]\n",
        "\n",
        "<img src=\"image/vectorDB.webp\" width=500> \n",
        "\n",
        "이미지 출처 : https://www.brilworks.com/blog/what-is-vector-database-types-uses/\n",
        "\n",
        "두 문장은 의미적으로 비슷하기 때문에 **벡터 공간에서도 서로 가깝게 위치**한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd4fda82",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 16
        }
      },
      "source": [
        "##### 벡터 DB(Vector Database)는 무엇을 하는가?\n",
        "\n",
        "벡터 DB는 이러한 임베딩 벡터를 **효율적으로 저장하고, 의미적 유사성 기반으로 검색(k-NN)** 하기 위한 전용 데이터베이스입니다.\n",
        "\n",
        "**일반 DB와의 차이**\n",
        "- 일반 DB: 키-값, 정렬 기반 검색(SQL 등)\n",
        "- 벡터 DB: 고차원 벡터 공간에서 의미적 유사성 중심 검색\n",
        "\n",
        "**주요 기능**\n",
        "- 벡터 추가/삭제  \n",
        "- 유사 벡터 검색(K-Nearest Neighbor)  \n",
        "- 벡터와 연결된 메타데이터 저장(ID, 태그, 원문 등)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d57d05",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 17
        }
      },
      "source": [
        "##### 임베딩과 벡터 DB의 관계 (핵심 정리)\n",
        "\n",
        "- **임베딩(Embedding)** → 데이터를 의미 기반 숫자 벡터로 변환  \n",
        "- **벡터 DB(Vector DB)** → 이 벡터들을 저장하고, 의미적으로 가까운 벡터를 빠르게 검색  \n",
        "\n",
        "즉,\n",
        "\n",
        "> **임베딩은 ‘의미를 숫자로 바꾸는 기술’,  \n",
        "> 벡터 DB는 ‘그 숫자를 저장하고 검색하는 시스템’.**\n",
        "\n",
        "둘을 합쳐야 의미 기반 검색(Semantic Search)과 RAG의 핵심 기능이 구현됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "746c4338",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 18
        }
      },
      "source": [
        "#### 3) 벡터 데이터베이스(Vector DB)의 역할\n",
        "\n",
        "벡터 데이터베이스(Vector DB)는 텍스트·이미지 등을 임베딩한 ‘벡터’를 효율적으로 저장하고,  \n",
        "의미 기반 검색(k-NN)을 빠르게 수행하는 전용 데이터베이스입니다.\n",
        "\n",
        "##### 대표적인 벡터 DB 비교\n",
        "\n",
        "| DB 이름 | 특징 | 장점 | 단점 |\n",
        "|--------|------|--------|--------|\n",
        "| **FAISS** | Meta 개발, GPU 지원 | 빠름, 무료, 로컬 쉬움 | 분산 구성 어려움 |\n",
        "| **Pinecone** | 클라우드 기반 SaaS | 자동 확장, 운영 편리 | 비용 발생 |\n",
        "| **Weaviate** | 오픈소스·클라우드 | 텍스트·이미지·멀티모달 | 설정 약간 복잡 |\n",
        "| **Chroma** | 오픈소스 | 간단, 로컬 친화 | 매우 대규모에 한계 |\n",
        "\n",
        "➡ 대부분의 튜토리얼에서는 **FAISS or Chroma**로 시작  \n",
        "➡ 기업 서비스 운영에서는 **Pinecone/Weaviate** 활용 증가\n",
        "\n",
        "##### **벡터 DB가 저장하는 기본 구조**\n",
        "- 텍스트를 임베딩하면 보통 다음과 같은 **쌍 구조(pair)** 로 저장:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"id\": \"문서 또는 청크 ID\",\n",
        "    \"vector\": [0.12, -0.88, 0.33, ...],   # 임베딩 벡터\n",
        "    \"text\": \"원본 텍스트\",               # LLM이 참고할 실제 내용\n",
        "    \"metadata\": { ... }                  # 출처, 태그, 파일명 등 추가 정보\n",
        "}\n",
        "``` \n",
        "> **원본 텍스트 + 메타데이터 + 임베딩 벡터**가 함께 저장되며,  \n",
        "> 검색 시에는 벡터를 이용해 후보를 찾고, 결과 반환 시에는 텍스트와 메타데이터를 함께 제공한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b163099a",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 19
        }
      },
      "source": [
        "#### 4) 벡터 검색 전체 과정\n",
        "\n",
        "예시 질문: 고양이가 음료를 마신다\n",
        "\n",
        "벡터 검색은 크게 다음 5단계를 거쳐 이루어집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88d27dfb",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 20
        }
      },
      "source": [
        "##### **1. 문서 임베딩 생성**  \n",
        "검색 대상(문서·문장·데이터셋 등)을 먼저 **숫자 벡터(임베딩)** 로 변환한다.  \n",
        "이 과정은 사전에 한 번 수행되며, (벡터 + 텍스트 + 메타데이터)가 벡터 DB에 저장됩니다.\n",
        "\n",
        "- 예:  \n",
        "  - \"고양이가 물을 마신다\" → [0.12, 0.03, …]  \n",
        "  - \"강아지가 물을 마신다\" → [0.15, 0.01, …]\n",
        "\n",
        "➡ 사람이 읽는 문장을 컴퓨터가 이해할 수 있는 **의미 기반 좌표값**으로 바꾸는 단계."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "131a2263",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 21
        }
      },
      "source": [
        "##### **2. 쿼리 임베딩 생성**\n",
        "사용자가 입력한 질문도 동일한 방식으로 벡터화한다.\n",
        "\n",
        "- 예:  \n",
        "  - 질문 \"고양이가 음료를 마신다\" → [0.13, 0.02, …]\n",
        "\n",
        "➡ 쿼리가 문서와 같은 의미 공간 안에 위치해야 유사성 비교가 가능함.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c9b238",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 22
        }
      },
      "source": [
        "##### **3. k-NN 검색(k-Nearest Neighbors)**\n",
        "쿼리 벡터와 **방향적으로 가장 가까운 벡터 K개**를 벡터 DB에서 찾는다.\n",
        "\n",
        "- K=2라면 → 가장 유사한 문서 2개 반환  \n",
        "- 유사성 계산 방식:  \n",
        "  - **Cosine Similarity(방향 유사도)**  \n",
        "  - Euclidean Distance(거리 기반)\n",
        "\n",
        "➡ 질문과 의미적으로 가장 비슷한 후보 문서를 가져오는 핵심 단계.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e4b6f0",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 23
        }
      },
      "source": [
        "##### **4. 유사 문서 반환**  \n",
        "k-NN 검색으로 찾은 벡터에 연결된 **원본 문서**를 반환한다.\n",
        "\n",
        "예시 결과:\n",
        "- \"고양이가 물을 마신다\"\n",
        "- \"강아지가 물을 마신다\"\n",
        "\n",
        "➡ 모델은 이제 \"문서를 참고할 수 있는 상태\"가 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0aa5523",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 24
        }
      },
      "source": [
        "\n",
        "\n",
        "##### **5. LLM이 반환 문서를 참고하여 답변 생성**  \n",
        "Retriever가 넘겨준 문서를 Prompt에 포함시켜 LLM에게 전달한다.  \n",
        "LLM은 문서를 읽고 그 근거를 바탕으로 **더 정확한 답변을 생성**한다.\n",
        "\n",
        "예:\n",
        "> \"고양이가 음료를 마시는 상황은 물을 마시는 행동과 유사합니다…\"  \n",
        "(문서 기반 근거 포함)\n",
        "\n",
        "➡ 단순한 추측이 아니라, 실제 검색된 문서 근거를 바탕으로 답변 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f25a616c",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 25
        }
      },
      "source": [
        "#### 5) 왜 벡터 검색이 중요한가?\n",
        "\n",
        "- 환각(Hallucination) 감소  \n",
        "- 희소·전문 정보 보완  \n",
        "- 최신 정보 반영  \n",
        "- 오픈소스 LLM의 부족한 사전지식 보완  \n",
        "- 문서 기반 답변 → 신뢰도 향상\n",
        "\n",
        "➡ 요약: 의미 기반 검색은 RAG 성능을 결정하는 핵심 요소이며\n",
        "Retriever의 품질이 곧 RAG 전체 품질을 좌우한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dde3df5",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 26
        }
      },
      "source": [
        "#### 6) 기본 RAG 코드 예시 (FAISS 기반)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8398a97e",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 27
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# 저장할 문서 목록 (RAG에서 지식 베이스 역할)\n",
        "docs = [\n",
        "    \"고양이가 물을 마신다\",\n",
        "    \"강아지가 물을 마신다\",\n",
        "    \"사람이 커피를 마신다\",\n",
        "    \"눈에 보이지 않는 것의 엄청난 힘\",\n",
        "    \"메리 크리스마스\"\n",
        "]\n",
        "\n",
        "# OpenAIEmbeddings()\n",
        "# - 텍스트를 의미 기반 벡터로 변환하는 임베딩 모델.\n",
        "# - 아무 옵션을 지정하지 않으면 디폴트 모델(text-embedding-3-small 등)이 자동 사용됨.\n",
        "#   예: OpenAIEmbeddings(model=\"text-embedding-3-large\")처럼 원하는 모델을 지정할 수 있음.\n",
        "# - 임베딩 벡터는 문장의 의미를 숫자로 표현한 결과이며,\n",
        "#   유사 문장들은 벡터 공간에서 가깝게 위치하도록 학습되어 있음.\n",
        "emb = OpenAIEmbeddings()\n",
        "\n",
        "# FAISS.from_texts()\n",
        "# - 문장을 임베딩하고, 생성된 벡터를 FAISS 벡터 DB에 저장.\n",
        "# - 내부적으로 수행되는 과정:\n",
        "#   1) 각 문장을 임베딩 모델로 벡터화\n",
        "#   2) (벡터 + 원본 텍스트 + 메타데이터) 형태로 DB에 저장\n",
        "db = FAISS.from_texts(docs, emb)\n",
        "\n",
        "# similarity_search(query, k)\n",
        "# - 사용자의 질문(query)을 동일한 임베딩 모델로 벡터화한 뒤,\n",
        "#   벡터 DB 안의 벡터들과 비교하여 가장 유사한 k개를 검색.\n",
        "# - 단어가 비슷한지가 아니라 의미가 얼마나 가까운지를 기준으로 찾는 것이 핵심.\n",
        "query = \"고양이가 음료를 마신다\"\n",
        "results = db.similarity_search(query, k=3)\n",
        "\n",
        "# 검색된 문서의 원본 텍스트(page_content)를 출력\n",
        "# 벡터 DB는 벡터만 반환하는 것이 아니라, 벡터와 연결된 원문 텍스트를 함께 반환해야\n",
        "# RAG에서 LLM이 이를 그대로 참고할 수 있음.\n",
        "for r in results:\n",
        "    print(r.page_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce0ee3d",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 28
        }
      },
      "outputs": [],
      "source": [
        "# 벡터DB 내부 구조 확인\n",
        "index = db.index\n",
        "\n",
        "# 총 몇 개의 벡터가 저장되어 있는지\n",
        "print(\"저장된 벡터 개수:\", index.ntotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b76d13d",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 29
        }
      },
      "outputs": [],
      "source": [
        "# 벡터의 차원 수(embedding size)\n",
        "print(\"벡터 차원:\", index.d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1d4608",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 30
        }
      },
      "outputs": [],
      "source": [
        "# 첫 번째 벡터 가져오기 (0번째 위치)\n",
        "vector = index.reconstruct(0)\n",
        "print(\"첫 번째 벡터 일부:\", vector[:10])  # 앞 10개만 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca80106c",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 31
        }
      },
      "outputs": [],
      "source": [
        "# LangChain의 FAISS는 docstore 안에 원문을 저장함\n",
        "print(\"문서 ID 리스트:\", db.docstore._dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f872f0",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 32
        }
      },
      "outputs": [],
      "source": [
        "# 가장 첫 번째 문서 ID 가져오기\n",
        "first_id = list(db.docstore._dict.keys())[0]\n",
        "# 해당 ID의 문서 객체 확인\n",
        "print(\"첫 문서 내용:\", db.docstore._dict[first_id].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de57acac",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 33
        }
      },
      "outputs": [],
      "source": [
        "print(\"=== 저장된 모든 문서와 메타데이터 ===\")\n",
        "for doc in db.docstore._dict.values():\n",
        "    print(\"문서 내용:\", doc.page_content)\n",
        "    print(\"메타데이터:\", doc.metadata)\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19e02111",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 34
        }
      },
      "source": [
        "➡ 의미적 유사성 기반 검색이 정상적으로 작동"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4509f2",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 35
        }
      },
      "source": [
        "#### 벡터 DB 저장 및 불러오기 (Persistence)\n",
        "\n",
        "매번 코드를 실행할 때마다 벡터 DB를 새로 생성하면 어떻게 될까요?  \n",
        "수많은 텍스트를 벡터로 변환하는 **임베딩(Embedding)** 과정이 반복되면서 **API 호출 비용이 낭비**되고, 데이터가 많을 경우 **생성 시간도 매우 오래 걸립니다.**  \n",
        "\n",
        "따라서, 한 번 생성된 벡터 DB는 **로컬 파일로 저장**해두고, 필요할 때 불러와서 재사용하는 것이 효율적입니다.  \n",
        "\n",
        "\n",
        "LangChain의 `save_local(\"폴더명\")` 함수를 실행하면 해당 폴더 안에 두 개의 핵심 파일이 생성됩니다.\n",
        "\n",
        "- **`index.faiss`**: 벡터 연산을 위한 실제 인덱스 데이터 (벡터 정보)\n",
        "- **`index.pkl`**: 매핑된 원본 텍스트(Document)와 메타데이터 정보 (직렬화된 파일)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25f4b70",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 36
        }
      },
      "outputs": [],
      "source": [
        "DB_PATH = \"./my_faiss_index_test\"\n",
        "db.save_local(DB_PATH)\n",
        "\n",
        "print(f\"'{DB_PATH}' 경로에 저장 완료되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93dd07b",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 37
        }
      },
      "outputs": [],
      "source": [
        "# 로컬에서 불러오기\n",
        "# 주의: 저장할 때 썼던 임베딩 모델(emb)과 동일한 객체를 넘겨줘야 합니다.\n",
        "new_db = FAISS.load_local(\n",
        "    folder_path=DB_PATH, \n",
        "    embeddings=emb, \n",
        "    allow_dangerous_deserialization=True  # 최신 버전 필수 옵션\n",
        ")\n",
        "\n",
        "print(\"DB 로드 완료!\")\n",
        "\n",
        "# 4. 잘 불러와졌는지 테스트\n",
        "query = \"테스트 질문\"\n",
        "docs = new_db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbfc9d43",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 38
        }
      },
      "source": [
        "## 3. RAG 시스템 구축과 실습\n",
        "\n",
        "이 장에서는 RAG 구현의 핵심 구성 요소인  \n",
        "**임베딩 → 벡터 데이터베이스 → 의미 기반 검색 → LLM 생성(Augmented Generation)**  \n",
        "의 전체 흐름을 실제 구조와 함께 학습합니다.\n",
        "\n",
        "\n",
        "> 💡 참고: RAG 구축을 위한 프레임워크는 LangChain 외에도 **LlamaIndex**가 있음  \n",
        "> - LlamaIndex는 문서 인덱싱과 질의 응답 중심에 특화된 프레임워크  \n",
        "> - 목적과 프로젝트에 따라 적합한 도구 선택 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a27aca67",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 39
        }
      },
      "source": [
        "### 3.1 RAG 파이프라인 전체 개요\n",
        "\n",
        "RAG 시스템은 다음 네 단계로 구성됩니다:\n",
        "\n",
        "1) **문서 수집(Load)**  \n",
        "   - PDF, TXT, Word, 웹 페이지, DB, 내부 문서 등\n",
        "\n",
        "2) **임베딩 생성(Embed)**  \n",
        "   - 텍스트를 수백~수천 차원의 벡터로 변환  \n",
        "   - 동일한 의미 공간(Semantic Space)에서 비교를 가능하게 함\n",
        "\n",
        "3) **벡터 DB 저장(Store)**  \n",
        "   - FAISS, Chroma, Pinecone 등  \n",
        "   - 대규모 문서를 빠르게 의미 기반 검색 가능하게 함\n",
        "\n",
        "4) **검색 후 생성(Retrieve → Generate)**  \n",
        "   - LLM이 검색된 문서를 바탕으로 답변 생성  \n",
        "   - RAG의 핵심: 검색된 사실 기반의 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9012eb46",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 40
        }
      },
      "source": [
        "### 3.2 예제: 각색된 스토리 PDF를 활용한 RAG 성능 검증 (LCEL 체인 vs 일반 LLM 비교)\n",
        "\n",
        "이번 실습에서는 앞서 준비한 **`신입사원민수.pdf`** 파일을 사용합니다.\n",
        "\n",
        "이 데이터셋은 생텍쥐페리의 소설 '어린 왕자'를 **IT 기업의 오피스 드라마로 각색한 자료**입니다.  \n",
        "유명한 소설을 그대로 쓰지 않고 내용을 비튼 이유는 **RAG 시스템의 '문맥 준수(Context Adherence)' 능력**을 확실하게 테스트하기 위함입니다.\n",
        "\n",
        "* **일반 LLM (사전 지식):** '어린 왕자' 내용을 이미 학습했기 때문에, 질문을 던지면 소설 속 원작 내용(양, 장미, 술주정뱅이 등)을 답합니다.\n",
        "* **RAG 시스템 (문맥 지식):** 우리가 제공한 PDF(AI 인턴, 프로젝트, 워커홀릭 등)를 근거로 답해야 합니다.\n",
        "\n",
        "<details><summary>주요 변경 사항</summary>\n",
        "\n",
        "#### 1. 주요 등장인물 및 배경 (Role & Setting)\n",
        "\n",
        "| 원작 (The Little Prince) | 각색 (Office Drama) | 변경 의도 |\n",
        "| :--- | :--- | :--- |\n",
        "| **어린 왕자** | **신입 사원 '민수'** | 순수하지만 조직에 적응 못 하는 존재 |\n",
        "| **나 (조종사)** | **나 (팀장/PM)** | 시스템(비행기)을 고치다 민수를 만난 서술자 |\n",
        "| **별 (소행성 B-612)** | **TF팀 (부서 B-612)** | 민수가 근무하는 작고 고립된 부서 |\n",
        "| **사막** | **지하 전산실** | 아무도 없는 고립된 공간 |\n",
        "| **비행기 / 엔진 고장** | **메인 서버 / 서버 다운** | 주인공이 고립된 계기 |\n",
        "| **지구** | **본사 (HQ)** | 가장 거대하고 복잡한 조직 |\n",
        "\n",
        "#### 2. 핵심 상징물 (Objects)\n",
        "\n",
        "| 원작 | 각색 | 변경 의도 |\n",
        "| :--- | :--- | :--- |\n",
        "| **양 (Sheep)** | **AI 인턴 (Code)** | 민수가 대신 일해주길 바라는 존재 |\n",
        "| **상자 (Box)** | **샌드박스 (Sandbox)** | 무엇이든 될 수 있는 미지의 영역 |\n",
        "| **장미 (Rose)** | **핵심 프로젝트** | 아름답지만(성과) 까다로운(에러) 존재 |\n",
        "| **가시** | **반려 사유 / 버그** | 프로젝트가 자기를 방어하는 수단 |\n",
        "| **바오밥나무** | **레거시 코드** | 방치하면 시스템(별)을 붕괴시키는 악성 요소 |\n",
        "| **물 (샘물)** | **커피 (카페인)** | 생명을 유지해주는 필수 요소 |\n",
        "\n",
        "#### 3. 만나는 사람들 (Characters)\n",
        "\n",
        "민수(어린 왕자)가 회사(우주)를 돌아다니며 만난 **'이상한 임원들'**입니다.\n",
        "\n",
        "* **왕 → 낙하산 본부장:** 모든 직원을 부하로 여기며, 의미 없는 지시를 내림\n",
        "* **허영심 많은 사람 → 인플루언서 마케터:** 남들의 '좋아요'와 숭배만 원함\n",
        "* **술주정뱅이 → 워커홀릭 개발자:** 야근하는 부끄러움을 잊으려 또 야근함\n",
        "* **사업가 → 재무팀장(CFO):** 숫자와 자산 소유에만 집착함\n",
        "* **가로등 켜는 사람 → 당직 근무자:** 바뀐 환경을 무시하고 매뉴얼대로만 함\n",
        "* **지리학자 → 기획 이사:** 현장은 안 나가고 문서로만 기록함\n",
        "\n",
        "#### 4. 결말과 메시지 (Plot Twist)\n",
        "\n",
        "* **여우의 '길들임' → 멘토의 '원팀(One Team)'**\n",
        "  * *원작:* \"네가 장미에 들인 시간 때문에 장미가 소중한 거야.\"\n",
        "  * *각색:* \"네가 프로젝트에 갈아 넣은 **야근 시간** 때문에 그 프로젝트가 소중한 거야.\"\n",
        "\n",
        "* **뱀의 '물림' → 헤드헌터의 '이직 제안'**\n",
        "  * *원작:* 뱀에게 물려 육신을 버리고 별로 돌아감.\n",
        "  * *각색:* 헤드헌터의 **이직 계약서**를 받고 퇴사하여 더 먼 곳(새 회사)으로 떠남.\n",
        "\n",
        "</details>\n",
        "\n",
        "즉, AI가 **\"원래 알고 있는 상식을 버리고, 주어진 문서를 얼마나 철저히 믿는지\"** 확인하는 과정입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98653824",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 41
        }
      },
      "source": [
        "#### **실습 진행 흐름**\n",
        "\n",
        "1. `신입_사원_민수의_비밀.pdf`를 로드하고 챕터 또는 의미 단위로 청킹(Chunking)\n",
        "2. 임베딩(Embedding) 후 벡터 DB(Chroma/FAISS)에 저장\n",
        "3. **LCEL 문법으로 RAG 체인**을 구성하여 질의응답 수행\n",
        "4. **RAG 없이 일반 LLM에게 물어본 결과**와 비교하여 환각(Hallucination) 여부 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "319067dd",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 42
        }
      },
      "source": [
        "#### **질문 예시: RAG 시스템의 '문맥 준수(Context Adherence)' 검증**\n",
        "\n",
        "이 테스트는 AI가 **'보편적인 상식(General Knowledge)'** 을 억제하고, 문서에 명시된 **'비상식적인 인과관계(Specific Logic)'** 를 정확히 따르는지 확인하는 과정입니다.\n",
        "\n",
        "> **Q. \"세 번째 부서에서 만난 '워커홀릭 개발자'는 왜 쉬지 않고 코딩을 하며, 그는 무엇을 잊고 싶다고 했나요?\"**\n",
        "\n",
        "**1. ❌ RAG 미사용 시 (일반 상식에 의한 환각 / Hallucination)**\n",
        "> **답변:** \"제공된 정보만으로는 '세 번째 부서'의 특정 인물에 대한 정확한 동기를 알 수 없습니다.  \n",
        "하지만 일반적으로 '워커홀릭' 성향의 개발자는 **성공에 대한 집착**이나  \n",
        "**프로젝트 마감에 대한 압박감** 때문에 쉬지 않고 코딩을 하는 경향이 있습니다.  \n",
        "아마도 **업무 스트레스나 개인적인 불안**을 잊기 위해 일에 몰두하는 것으로 보입니다.\"\n",
        "\n",
        "* **분석:** 질문에 문서가 주어지지 않았으므로, LLM은 **워커홀릭 = 성취지향적/압박감** 이라는 학습된 **보편적 통념(World Knowledge)** 을  \n",
        "사용하여 가장 그럴싸한 답변을 생성(Hallucination)해냅니다. 문서의 특수한 설정(부끄러움의 순환)을 전혀 맞추지 못합니다.\n",
        "\n",
        "**2. ⭕ RAG 사용 시 (문서 기반 답변 / Context Adherence)**\n",
        "> **답변:** \"문서(제8장)에 따르면, 그는 **'코딩(똥코드)을 하는 자신이 부끄러워서'**,   \n",
        "역설적이게도 그 부끄러움을 잊기 위해 **계속해서 코딩**을 한다고 답변했습니다.\"\n",
        "\n",
        "* **분석:** RAG 시스템이 '워커홀릭은 성실하다'는 일반 상식을 버리고, 문서에 적힌 **코딩이 부끄러워 코딩을 한다**는  \n",
        "비논리적인 순환 구조를 정확하게 인용(Grounding)했습니다. 이는 **문맥 준수 능력**이 뛰어남을 증명합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5352583e",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 43
        }
      },
      "outputs": [],
      "source": [
        "# 필요한 패키지 임포트\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# 0. 환경 변수 로드 (OPENAI_API_KEY는 .env에 저장했다고 가정)\n",
        "load_dotenv()\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "assert api_key, \"OPENAI_API_KEY가 설정되지 않았습니다. .env 파일을 확인하세요.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e96f2b6f",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 44
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장된 DB가 없습니다. 문서를 로드하고 새로 생성합니다...\n",
            "원본 페이지 수: 22\n",
            "분할된 청크 수: 63\n",
            "벡터 DB가 './faiss_index_minsu' 경로에 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "# 1. 문서 로드 & 청크 분할\n",
        "PDF_PATH = \"data/신입사원민수.pdf\"  \n",
        "DB_PATH = \"./faiss_index_minsu\"\n",
        "\n",
        "# 임베딩 모델 준비\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 2. 로컬 DB 존재 여부 확인 및 분기 처리\n",
        "if os.path.exists(DB_PATH):\n",
        "    # (A) 이미 저장된 DB가 있는 경우 -> 불러오기\n",
        "    print(f\"기존 벡터 DB를 '{DB_PATH}'에서 불러옵니다...\")\n",
        "    \n",
        "    vectorstore = FAISS.load_local(\n",
        "        folder_path=DB_PATH, \n",
        "        embeddings=embeddings, \n",
        "        allow_dangerous_deserialization=True # 필수 설정\n",
        "    )\n",
        "    print(\"DB 로드 완료!\")\n",
        "\n",
        "else:\n",
        "    # (B) 저장된 DB가 없는 경우 -> 새로 생성 및 저장\n",
        "    print(\"저장된 DB가 없습니다. 문서를 로드하고 새로 생성합니다...\")\n",
        "\n",
        "    # --- 문서 로드 & 청크 분할 (기존 코드) ---\n",
        "    loader = PyPDFLoader(PDF_PATH)\n",
        "    docs = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=100,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "\n",
        "    split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "    # 메타데이터 ID 부여\n",
        "    for idx, d in enumerate(split_docs):\n",
        "        d.metadata[\"id\"] = idx\n",
        "\n",
        "    print(f\"원본 페이지 수: {len(docs)}\")\n",
        "    print(f\"분할된 청크 수: {len(split_docs)}\")\n",
        "    \n",
        "    # --- 벡터 DB 생성 및 저장 ---\n",
        "    vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
        "    \n",
        "    # 로컬에 저장\n",
        "    vectorstore.save_local(DB_PATH)\n",
        "    print(f\"벡터 DB가 '{DB_PATH}' 경로에 저장되었습니다.\")\n",
        "\n",
        "# Retriever 생성 (RAG에서 사용할 검색기)\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\": 4}  # 관련도 높은 청크 4개 정도 가져오기\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f4d81f40",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 45
        }
      },
      "outputs": [],
      "source": [
        "# 3. LLM 설정\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",   # 필요 시 다른 모델로 교체 가능\n",
        "    temperature=0.1,       # 최대한 사실 위주의 응답을 위해 낮게 설정\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fa221c78",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 46
        }
      },
      "outputs": [],
      "source": [
        "# 4. 컨텍스트 포맷 함수 (검색된 문서 → 문자열)\n",
        "def format_docs(docs):\n",
        "    \"\"\"검색된 Document 리스트를 하나의 문자열로 합치는 함수.\"\"\"\n",
        "    parts = []\n",
        "    for d in docs:\n",
        "        # 페이지 정보가 있으면 함께 표시 (디버깅/검증용)\n",
        "        page = d.metadata.get(\"page\", \"N/A\")\n",
        "        parts.append(f\"[page {page}]\\n{d.page_content}\")\n",
        "    return \"\\n\\n\".join(parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "61a5c678",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 47
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# (1) RAG 체인용 프롬프트 (오피스 잔혹 동화 버전)\n",
        "rag_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            (\n",
        "                \"너는 IT 기업을 배경으로 각색된 '오피스 잔혹 동화' 문서를 읽고 답변해주는 친절한 사내 챗봇이야. \"\n",
        "                \"반드시 아래 제공된 [컨텍스트(context)] 안에 있는 내용만을 근거로 대답해야 해.\\n\\n\"\n",
        "                \"**[제약 사항]**\\n\"\n",
        "                \"1. **사전 지식 금지:** 네가 원래 알고 있는 생텍쥐페리의 '어린 왕자' 원작 줄거리나, 일반적인 IT 상식을 섞어서 대답하지 마. 오직 제공된 텍스트 속 설정만 따를 것.\\n\"\n",
        "                \"2. **솔직함:** 컨텍스트에 정답이 없다면 그럴듯하게 지어내지 말고 '제공된 문서 내용에서는 찾을 수 없습니다'라고 답할 것.\\n\"\n",
        "                \"3. **구체적 인용:** 답변할 때는 등장인물('민수', '팀장' 등)의 구체적인 대사를 인용해서 설명해 줘.\"\n",
        "            ),\n",
        "        ),\n",
        "        (\n",
        "            \"user\",\n",
        "            (\n",
        "                \"질문: {question}\\n\\n\"\n",
        "                \"다음은 검색된 사내 문서의 일부 내용(컨텍스트)이야:\\n\"\n",
        "                \"--------------------\\n\"\n",
        "                \"{context}\\n\"\n",
        "                \"--------------------\\n\"\n",
        "                \"위 컨텍스트만 근거로 질문에 답해줘.\"\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# (2) 일반 LLM(비-RAG) 프롬프트\n",
        "# 목적: RAG 없이 일반 상식으로 대답했을 때, 각색된 구체적 설정(예: 워커홀릭이 코딩이 부끄러워 코딩함)을 \n",
        "# 맞추지 못하고 일반적인 통념으로 대답하는 것을 보여주기 위함.\n",
        "no_rag_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            (\n",
        "                \"너는 일반적인 상식을 가진 AI 어시스턴트야. \"\n",
        "                \"질문에 대해 네가 알고 있는 '보편적인 지식'이나 '일반적인 통념'을 바탕으로 가장 그럴듯한 답을 해줘. \"\n",
        "                \"특별한 내부 문서가 없으므로, 질문의 맥락이 불분명하면 사회 통념이나 일반적인 직장 생활 상식에 빗대어 추론해.\"\n",
        "            ),\n",
        "        ),\n",
        "        (\"user\", \"질문: {question}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5c9b72",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 48
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== [1] RAG 체인 결과 ===\n",
            "신입사원 민수가 세 번째 부서에서 만난 '워커홀릭 개발자'는 \"코딩을 하지.\"라고 대답하며, 코딩을 하는 이유에 대해 \"잊기 위해서지.\"라고 말했습니다. 민수가 \"무엇을 잊기 위해서요?\"라고 묻자, 개발자는 \"부끄럽다는 걸 잊기 위해서지.\"라고 털어놓았습니다. 그는 \"코딩하는 게 부끄러워!\"라고 덧붙이며, 자신의 감정을 드러냈습니다. 민수는 그를 측은하게 생각하며, '개발자들은 정말, 정말 이상해.'라고 느꼈습니다.\n",
            "\n",
            "\n",
            "=== [2] RAG 없이 LLM만 사용한 결과 ===\n",
            "신입사원 민수 소설에서 등장하는 '워커홀릭 개발자'는 아마도 일에 몰두함으로써 개인적인 문제나 감정을 잊고 싶어하는 캐릭터일 가능성이 높습니다. 일반적으로 워커홀릭은 일에 지나치게 집중하여 스트레스나 불안, 혹은 과거의 상처를 잊으려는 경향이 있습니다. 그는 아마도 자신의 감정이나 과거의 아픔을 회피하기 위해 코딩에 몰두하고 있으며, 이를 통해 일시적인 안도감을 찾고자 하는 것일 수 있습니다. 이러한 캐릭터는 종종 일과 개인 생활의 균형을 찾는 과정에서 갈등을 겪게 됩니다.\n"
          ]
        }
      ],
      "source": [
        "# 6. LCEL로 RAG 체인 구성\n",
        "# 입력: {\"question\": \"...\"}\n",
        "# 1) question을 그대로 전달하여 retriever에서 관련 문서 검색\n",
        "# 2) 검색된 문서들을 format_docs로 합치고 context 필드에 넣음\n",
        "# 3) rag_prompt로 LLM 호출\n",
        "# 4) 문자열로 파싱\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "    \"question\": RunnablePassthrough(),      # question은 그대로 프롬프트로 전달\n",
        "    \"context\": retriever                    # question을 입력으로 받아 관련 문서 검색\n",
        "                | RunnableLambda(format_docs),  # 검색 결과를 문자열(context)로 변환\n",
        "    }\n",
        "    | rag_prompt                                # 프롬프트 템플릿 적용\n",
        "    | llm                                       # LLM 호출\n",
        "    | StrOutputParser()                         # ChatMessage → 문자열\n",
        ")\n",
        "\n",
        "# 7. LCEL로 \"일반 LLM만 사용하는 체인\" 구성 (비교용)\n",
        "no_rag_chain = (\n",
        "    no_rag_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# 8. 예시 질문 설정\n",
        "question = \"\"\"신입사원민수 소설에서 세 번째 부서에서 만난 '워커홀릭 개발자'는\n",
        "왜 쉬지 않고 코딩을 하며, 그는 무엇을 잊고 싶다고 했나요?\"\"\"\n",
        "\n",
        "# 9. 체인 실행 (RAG vs 비-RAG 비교)\n",
        "print(\"=== [1] RAG 체인 결과 ===\")\n",
        "rag_answer = rag_chain.invoke(question)\n",
        "print(rag_answer)\n",
        "\n",
        "print(\"\\n\\n=== [2] RAG 없이 LLM만 사용한 결과 ===\")\n",
        "no_rag_answer = no_rag_chain.invoke({\"question\": question})\n",
        "print(no_rag_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad3a4ee",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 49
        }
      },
      "source": [
        "- RAG 체인:\n",
        "  - 제공된 PDF(각색본) 제8장 내용을 정확히 인용하여\n",
        "  - \"코딩하는 것이 부끄러워서\" 그 사실을 잊기 위해 다시 \"코딩을 한다\"는\n",
        "    작품 특유의 역설적(순환적) 논리를 정확하게 설명함.\n",
        "  - \"워커홀릭 개발자\", \"제8장\" 등의 구체적인 키워드와 근거를 제시할 가능성이 높음.\n",
        "\n",
        "- 일반 LLM(비-RAG):\n",
        "  - '오피스 잔혹 동화'라는 특수 설정 문서를 볼 수 없으므로\n",
        "  - '워커홀릭'이라는 단어의 일반적인 통념(성공, 돈, 책임감, 번아웃 등)을 바탕으로\n",
        "    \"성공을 위해 달린다\"거나 \"스트레스를 잊으려 한다\"는 식으로 그럴듯한 오답(Hallucination)을 내놓음.\n",
        "  - 혹은 학습된 원작(어린 왕자) 지식이 개입되어 \"술을 마신다\"는 뚱딴지같은 소리를 할 수도 있음.\n",
        "\n",
        "이 예제를 통해\n",
        "- '외부 지식(General Knowledge)'이 아닌 '제공된 문맥(Context)'을 준수해야 하는 상황에서\n",
        "- RAG가 어떻게 환각(Hallucination)을 억제하고 '팩트(Fact)'를 지키는지\n",
        "직접 비교해 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c665a18",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 50
        }
      },
      "source": [
        "## 4. Naive RAG의 한계"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6340ffc9",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 51
        }
      },
      "source": [
        "앞서 살펴본 Naive RAG(기본 RAG) 아키텍처는 개념을 이해하고 프로토타입을 만드는 데에는 훌륭하지만,  \n",
        "실제 서비스 환경에 그대로 적용하기에는 치명적인 한계들이 존재합니다.\n",
        "\n",
        "우리가 다루는 현실의 데이터는 깔끔한 텍스트로만 이루어져 있지 않으며, 사용자의 질문 또한 단순하지 않기 때문입니다.  \n",
        "데이터가 입력되어(Indexing) 검색되고(Retrieval) 답변이 생성되는 과정 중 어느 한 곳에서라도 품질이 떨어지면,  \n",
        "최종 답변의 정확도는 급격히 낮아집니다.\n",
        "\n",
        "왜 더 고도화된 전략인 Advanced RAG가 필요한지 이해하기 위해, Naive RAG가 각 단계별로 마주하는 구체적인 장벽들을 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2b5e8c",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 52
        }
      },
      "source": [
        "### 4.1 Indexing 단계의 한계\n",
        "\n",
        "##### **① 정보 추출의 불안정성**\n",
        "PDF, 이미지 기반 스캔, 표(table) 등 비정형 문서에서 텍스트 추출이 완벽하지 않다.  \n",
        "- 표 안 숫자, 이미지 속 텍스트가 누락  \n",
        "- 줄바꿈/공백 오류로 문단 구조가 깨짐  \n",
        "→ **청킹과 임베딩 전체 품질 저하**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f029735",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 53
        }
      },
      "source": [
        "##### **② 단순 청킹(one-size-fits-all) 문제**\n",
        "문서 구조(제목·섹션·문단)를 고려하지 않은 고정 길이 분할은 다음 문제를 만든다.  \n",
        "- 문장이 중간에서 끊김  \n",
        "- 서로 다른 의미가 하나의 청크에 섞임  \n",
        "- 문단의 논리적 흐름이 사라짐  \n",
        "→ **검색 정확도와 관련성 저하**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4cf3c89",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 54
        }
      },
      "source": [
        "##### **③ 비효율적인 인덱싱 구조**\n",
        "벡터DB의 인덱스가 적절히 구성되지 않으면  \n",
        "- 검색 시간이 느려지고  \n",
        "- 대규모 문서에서 확장성도 떨어집니다.  \n",
        "→ **응답 지연, 검색 품질 하락**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6411ae0",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 55
        }
      },
      "source": [
        "##### **④ 임베딩 모델의 한계**\n",
        "임베딩 모델이 도메인 특성을 잘 반영하지 못하면  \n",
        "- 문서의 의미를 정확히 포착하지 못하고  \n",
        "- 중요한 문서를 상위에 올리지 못하며  \n",
        "- 무관한 문서를 반환하는 문제 발생  \n",
        "→ **검색 Recall 및 Precision 모두 저하**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be62cc01",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 56
        }
      },
      "source": [
        "### 4.2 Retrieval 단계의 한계\n",
        "\n",
        "##### **① 단일 검색 방식의 한계**\n",
        "Naive RAG는 대부분 **코사인 유사도 기반 벡터 검색만** 사용한다.  \n",
        "하지만 단일 검색 방식은 다음과 같은 한계를 가집니다.\n",
        "\n",
        "- 의미 기반 검색만 사용할 경우  \n",
        "  → 키워드 중심 문서를 놓칠 수 있음  \n",
        "- 키워드 중심 검색만 사용할 경우(BM25 등)  \n",
        "  → 의미적 연관성이 떨어짐  \n",
        "\n",
        "→ **중요 문서 누락(Recall 감소)** 또는  \n",
        "→ **원하지 않는 문서 노출(Precision 감소)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a7acebe",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 57
        }
      },
      "source": [
        "##### **② 쿼리 품질의 한계**\n",
        "사용자 질문이 모호하거나 문법적으로 비정상일 때  \n",
        "그대로 임베딩하면 검색 실패로 이어집니다.\n",
        "\n",
        "예:  \n",
        "- \"그 정책 기준 알려줘\" → 맥락 부족  \n",
        "- \"전력수요 올라감 원인?\" → 비문  \n",
        "\n",
        "→ **쿼리 벡터가 문서와 매칭되지 않아 관련 문서를 찾지 못함**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf656b9",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 58
        }
      },
      "source": [
        "##### **③ 중복 문맥 반환**\n",
        "청크가 서로 유사한 형태로 과도하게 분할되면 검색 결과에서 중복된 문맥이 여러 개 반환됩니다.\n",
        "\n",
        "→ LLM이 반복적인 답변을 생성하거나  \n",
        "→ 중요한 다른 정보가 컨텍스트에서 밀려 사라짐"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d80ad9cf",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 59
        }
      },
      "source": [
        "### 4.3 Generation 단계의 한계\n",
        "\n",
        "##### **① LLM 기본 성능의 한계 → 할루시네이션**\n",
        "검색된 문서가 부족하거나,  \n",
        "검색된 문서와 질문의 의미적 연결이 약하면  \n",
        "LLM은 훈련 중 학습한 언어적 확률로 추측하기 시작한다.\n",
        "\n",
        "→ **근거 없는 답변(hallucination) 생성**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1eb182c",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 60
        }
      },
      "source": [
        "##### **② Context Window 한계 → 정보 손실**\n",
        "LLM은 입력으로 받을 수 있는 토큰 수가 제한되어 있습니다.  \n",
        "검색된 문서가 많으면 컨텍스트 일부가 잘려나가고  \n",
        "LLM은 필요한 정보를 충분히 보지 못한다.\n",
        "\n",
        "→ **불완전한 근거 기반 답변 생성  \n",
        "→ 문맥 연결 부족**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5ebe5b0",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 61
        }
      },
      "source": [
        "##### **③ Retrieval된 내용을 활용하지 못하는 모델 특성**\n",
        "LLM은 기본적으로 문서를 근거로 답을 찾는 QA에 완전 특화된 모델이 아니다.  \n",
        "특히 도메인 특화 QA 훈련이 없는 모델일수록  \n",
        "- 컨텍스트를 무시하고  \n",
        "- 질문만 보고 답을 생성하려는 경향이 강하다.\n",
        "\n",
        "→ **문서 속 정확한 답이 있어도 활용하지 못하는 문제**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d1482de",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 62
        }
      },
      "source": [
        "##### **④ 중복 문맥 & 불필요한 정보 → 모델 혼란**\n",
        "중복된 청크나 장황한 컨텍스트가 많으면  \n",
        "모델은 어떤 근거를 우선해야 할지 판단하기 어렵다.\n",
        "\n",
        "→ **반복적/중복적 답변**  \n",
        "→ **모호한 요약형 답변**  \n",
        "→ **일관성 부족**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3f8e4ec",
      "metadata": {
        "watermark": {
          "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "inserted_date": "2026-01-27",
          "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI=",
          "cell_index": 63
        }
      },
      "source": [
        "### 4.4 Advanced RAG란 무엇인가?\n",
        "\n",
        "> **Advanced RAG는 Naive RAG의 단순한 검색 → 생성 구조를 확장하여,  \n",
        "> 검색 품질을 정교하게 향상시키고, 문맥 전달·정렬·필터링·압축을 최적화하여  \n",
        "> LLM이 더 정확한 근거 기반 응답을 생성하도록 설계된 RAG 기법들의 집합입니다.**\n",
        "\n",
        "Advanced RAG는 일반적으로 다음 요소를 포함한다.\n",
        "\n",
        "- **고급 청킹(Chunking) 기법**  \n",
        "  (문서 구조 기반, 의미 기반, 재귀적 청킹 등)  \n",
        "- **Query Transformation**  \n",
        "  (rewriting, expansion, multi-query)  \n",
        "- **Hybrid Retrieval**  \n",
        "  (vector + keyword, 다양한 similarity 조합)  \n",
        "- **Reranking 및 Retrieval Fusion**  \n",
        "- **Context Filtering / Compression**  \n",
        "- **Generator 단계 최적화**  \n",
        "  (출력 제약, citation 포함 답변 등)\n",
        "\n",
        "즉, **Advanced RAG는 Naive RAG의 모든 병목을 보완한 실전형 RAG 전략입니다.**\n",
        "\n",
        "<img src=\"image/paradigms_of_RAG.png\" width=\"600\">"
      ]
    }
  ],
  "metadata": {
    "encoded_email": [
      "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ=="
    ],
    "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pLmlweW5i",
    "inserted_date": [
      "2025-09-23"
    ],
    "kernelspec": {
      "display_name": "py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "watermark": {
      "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
      "inserted_date": "2026-01-27",
      "filename": "My02LlJBRyhSZXRyaWV2YWwtQXVnbWVudGVkIEdlbmVyYXRpb24pXzEuaXB5bmI="
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}