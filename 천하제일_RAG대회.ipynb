{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c176a379",
   "metadata": {},
   "source": [
    "## 🏆 천하제일 RAG 대회\n",
    "\n",
    "지금까지 우리는 RAG 성능을 최적화하기 위한  \n",
    "다양한 기법과 전략들을 단계적으로 학습해 왔습니다.\n",
    "\n",
    "이제 그동안 배운 내용을 종합해,  \n",
    "**가장 정확하고 효율적인 RAG 챗봇**을 직접 만들어보는 미션에 도전합니다.\n",
    "\n",
    "\n",
    "이번 대회에서 사용하는 문서는  **『오피스 잔혹 동화: 신입 사원 민수』 PDF**입니다.\n",
    "\n",
    "해당 문서는 널리 알려진 작품(예: *어린 왕자*)의 **서사 구조를 참고하되**,  \n",
    "평가 목적에 맞게 **일부 설정과 표현이 변형된 비공개 텍스트**입니다.\n",
    "\n",
    "따라서 이번 미션의 핵심은 상식이나 사전학습 지식에 의존해 답을 맞히는 것이 아니라,  \n",
    "**Retriever가 실제로 찾아온 문서 근거를 얼마나 잘 활용하느냐**에 있습니다.\n",
    "\n",
    "\n",
    "참가자는 이미 제공된 PDF 데이터를 기반으로, 질문에 대해 문서에서 관련 근거를 검색하고  \n",
    "**정답만 간결하게 출력하는 챗봇**을 구현하게 됩니다.\n",
    "\n",
    "\n",
    "🏅 **1등 수상자에게는 상금(50000) 또는 맛있는 식사가 제공됩니다.**\n",
    "\n",
    "※ 점수가 동일할 경우  \n",
    "- **k 값이 더 작은 설정**,  \n",
    "- **청크 길이가 더 짧은 설정**\n",
    "- **코드에 주석을 친절히 작성한**  참가자를  \n",
    "우선 순위로 1등으로 선정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1245edc",
   "metadata": {},
   "source": [
    "### 💬 평가 질문(20개)\n",
    "💬 질문: 이야기의 제목은 무엇인가요? | 📘 정답: 오피스 잔혹 동화: 신입 사원 민수  \n",
    "💬 질문: 민수가 처음 등장하는 장소는 어디인가요? | 📘 정답: 본사 지하 전산실  \n",
    "💬 질문: 민수가 처음 요구한 것은 무엇인가요? | 📘 정답: AI 인턴 하나를 코딩해 달라는 요청  \n",
    "💬 질문: 민수가 싫어한다고 말한 아키텍처 구조는 무엇인가요? | 📘 정답: 모놀리식(Monolithic) 구조  \n",
    "💬 질문: 민수가 원하는 AI 인턴의 조건 중 하나는 무엇인가요? | 📘 정답: 오래 유지보수할 수 있는 구조여야 함  \n",
    "💬 질문: 민수가 속한 부서의 코드명으로 추정되는 이름은 무엇인가요? | 📘 정답: 부서 B-612  \n",
    "💬 질문: 부서 B-612는 어떤 특징을 가진 조직으로 묘사되나요? | 📘 정답: 회의실 하나보다도 작은 규모의 TF 조직  \n",
    "💬 질문: 민수는 레거시 코드를 어떻게 인식하고 있나요? | 📘 정답: 초기에 정리하지 않으면 시스템 전체를 망가뜨리는 위험 요소  \n",
    "💬 질문: 민수가 좋아한다고 명확히 언급한 근무 방식은 무엇인가요? | 📘 정답: 칼퇴  \n",
    "💬 질문: 민수가 “로딩 바 100%를 마흔네 번 봤다”고 말한 이유는 무엇인가요? | 📘 정답: 극심한 번아웃 상태를 비유적으로 표현한 것  \n",
    "💬 질문: 민수가 사랑한다고 표현한 것은 무엇인가요? | 📘 정답: 핵심 프로젝트  \n",
    "💬 질문: 핵심 프로젝트는 어떤 특성을 가진 것으로 묘사되나요? | 📘 정답: 기능이 단순하지만 민수에게 의미 있는 프로젝트  \n",
    "💬 질문: 민수가 퇴사 전 마지막으로 정리한 것은 무엇인가요? | 📘 정답: 실행 중인 프로세스들과 레거시 코드 주석  \n",
    "💬 질문: 이야기에서 ‘본부장’ 캐릭터는 어떤 인물로 표현되나요? | 📘 정답: 권위와 지시를 중시하는 낙하산형 관리자  \n",
    "💬 질문: ‘재무팀장’은 자산을 어떻게 다루는 인물로 묘사되나요? | 📘 정답: 자산을 사용하지 않고 소유와 관리만 하는 인물  \n",
    "💬 질문: 민수가 만난 ‘당직 근무자’의 역할은 무엇인가요? | 📘 정답: 서버 모니터링과 로그 확인을 반복하는 역할  \n",
    "💬 질문: 민수가 본사에서 만난 헤드헌터는 어떤 존재로 비유되나요? | 📘 정답: 뱀  \n",
    "💬 질문: 민수가 찾고자 했던 ‘원팀(One Team)’의 의미는 무엇인가요? | 📘 정답: 단순한 조직이 아니라 관계를 맺은 동료 관계  \n",
    "💬 질문: 이 작품에서 민수의 정확한 나이는 언급되나요? | 📘 정답: 없는 정보 \n",
    "💬 질문: 민수가 다니는 회사의 실제 회사명은 무엇인가요? | 📘 정답: 없는 정보  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c9094e",
   "metadata": {},
   "source": [
    "### 💡미션\n",
    "완성된 챗봇은 **『오피스 잔혹 동화: 신입 사원 민수』 PDF**를 기반으로 질문에 답변해야 합니다.\n",
    "\n",
    "- 문서에 정보가 없는 경우는 반드시 **\"없는 정보\"** 로 답변해야 합니다.\n",
    "- **문서 근거 기반(Fact-grounded)** 의 신뢰도 높은 답변을 제공할 것\n",
    "- 검색 성능 향상을 위해 **chunking / k / retriever 설정 등**을 조정하는 것을 권장합니다\n",
    "- 사용 모델은 바꿔도 되나, **비용이 더 저렴한 모델로만** 변경 가능합니다\n",
    "\n",
    "※ 제공된 코드는 시작이 막막한 경우를 위한 Baseline 코드입니다.  \n",
    "Baseline은 정답이 아니며, 그동안 학습한 다양한 RAG 기법을 적용해 성능을 개선해 보는 것이 이번 미션의 핵심입니다.  \n",
    "Retriever 설정, 문서 분할 방식, 프롬프트 설계 등을 자유롭게 수정하여 더 정확한 답변을 만들어 보세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6217bf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os  # OS 모듈: 파일 경로 및 디렉토리 조작, 환경변수 접근 등을 위해 사용\n",
    "from langchain_community.document_loaders import PyPDFLoader  # PDF 파일을 페이지 단위 Document 객체로 로드하는 로더\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  # 텍스트 분할기: 긴 문서를 지정한 크기와 겹침 설정으로 쪼개주는 분할기\n",
    "from langchain_community.vectorstores import FAISS  # 벡터 저장소: 문서 임베딩 벡터를 저장하고 유사도 기반 검색을 위한 FAISS\n",
    "from langchain_openai import OpenAIEmbeddings  # OpenAI의 텍스트 임베딩 모델(text-embedding-3 등)을 사용하는 모듈\n",
    "from langchain_openai import ChatOpenAI  # OpenAI의 챗 모델(GPT-4, GPT-4o 등)을 사용하는 모듈\n",
    "from langchain_core.prompts import ChatPromptTemplate  # LLM에 전달할 메시지를 템플릿 형태로 구성하기 위한 모듈\n",
    "from langchain_core.output_parsers import StrOutputParser  # LLM의 응답 중 문자열만 깔끔히 추출해주는 파서\n",
    "from langchain_core.runnables import RunnablePassthrough  # LCEL 체인에서 입력 값을 그대로 다음 단계로 전달하기 위한 Runnable (컨텍스트/질문 병렬 전달 등에 사용)\n",
    "from grading_utils import grade_predictions  # 모델이 생성한 답변을 정답 기준으로 평가하는 채점 함수\n",
    "from grading_utils import answer_key  # 채점에 사용되는 정답(ground truth) 리스트\n",
    "from dotenv import load_dotenv  # .env 파일에 정의된 환경 변수(API 키 등)를 현재 실행 환경에 로드\n",
    "load_dotenv()  # .env 파일의 내용을 읽어 os.environ에 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb93aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 채점 결과에서 점수 추출 유틸\n",
    "def extract_scores(llm_output: str):\n",
    "    \"\"\"\n",
    "    LLM 채점 출력에서 항목별 점수를 추출하고 총점을 계산합니다.\n",
    "\n",
    "    Input 예시:\n",
    "      \"1번: 1점 (정확)\\n2번: 0.5점 (부분정확)\\n...\"\n",
    "\n",
    "    Output:\n",
    "      (총점(float), 항목별 점수(list[float]))\n",
    "    \"\"\"\n",
    "    score_pattern = re.compile(r\"\\d+번:\\s*([01](?:\\.5)?)점\")\n",
    "    scores = score_pattern.findall(llm_output)\n",
    "    scores = list(map(float, scores))\n",
    "    total = sum(scores)\n",
    "    return total, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e502cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 기존 FAISS 인덱스를 로드합니다.\n"
     ]
    }
   ],
   "source": [
    "# 1) PDF 문서 로딩 (단일 문서)\n",
    "PDF_PATH = \"data/신입사원민수.pdf\"\n",
    "FAISS_INDEX_PATH = \"faiss_index_minsu1\"\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# 1) FAISS 인덱스가 이미 존재하면 로드\n",
    "if os.path.exists(FAISS_INDEX_PATH):\n",
    "    print(\"✅ 기존 FAISS 인덱스를 로드합니다.\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        FAISS_INDEX_PATH,\n",
    "        embedding_model,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "# 2) 없으면 PDF → 분할 → 임베딩 → 저장\n",
    "else:\n",
    "    print(\"🆕 FAISS 인덱스가 없어 새로 생성합니다.\")\n",
    "\n",
    "    # PDF 로딩\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # 텍스트 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "    # FAISS 생성\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        split_docs,\n",
    "        embedding_model\n",
    "    )\n",
    "\n",
    "    # 로컬 저장\n",
    "    vectorstore.save_local(FAISS_INDEX_PATH)\n",
    "    print(f\"FAISS 인덱스를 '{FAISS_INDEX_PATH}' 경로에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf7d7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 질문 1: 이야기의 제목은 무엇인가요?\n",
      "→ 예측: 없는 정보 | 정답: 오피스 잔혹 동화: 신입 사원 민수\n",
      "\n",
      "💬 질문 2: 민수가 처음 등장하는 장소는 어디인가요?\n",
      "→ 예측: 부서 325, 326, 327, 328, 329, 330호 근처입니다. | 정답: 본사 지하 전산실\n",
      "\n",
      "💬 질문 3: 민수가 처음 요구한 것은 무엇인가요?\n",
      "→ 예측: 민수가 처음 요구한 것은 \"칼퇴를 하고 싶어요... 저에게 결재를 해주셔서 퇴근하도록 지시해 주세요.\"입니다. | 정답: AI 인턴 하나를 코딩해 달라는 요청\n",
      "\n",
      "💬 질문 4: 민수가 싫어한다고 말한 아키텍처 구조는 무엇인가요?\n",
      "→ 예측: 없는 정보 | 정답: 모놀리식(Monolithic) 구조\n",
      "\n",
      "💬 질문 5: 민수가 원하는 AI 인턴의 조건 중 하나는 무엇인가요?\n",
      "→ 예측: 민수가 원하는 AI 인턴의 조건 중 하나는 '쓰기 권한(Write Permission)'입니다. | 정답: 오래 유지보수할 수 있는 구조여야 함\n",
      "\n",
      "💬 질문 6: 민수가 속한 부서의 코드명으로 추정되는 이름은 무엇인가요?\n",
      "→ 예측: 부서 B-612 | 정답: 부서 B-612\n",
      "\n",
      "💬 질문 7: 부서 B-612는 어떤 특징을 가진 조직으로 묘사되나요?\n",
      "→ 예측: 부서 B-612는 외부 컨설턴트에 의해 2020년에 한 번 보고서에 언급되었고, 임원들이 숫자를 좋아해 부서 코드로 인식되는 경향이 있다. 이 부서는 명성이 좋지 않았으나, 모기업 회장이 정장을 입도록 강요한 후 컨설턴트가 세련된 수트를 입고 발표하자 신뢰를 얻었다. 또한, 임원들은 실무자의 개인적인 특성보다는 숫자와 데이터에 기반한 정보를 선호한다. | 정답: 회의실 하나보다도 작은 규모의 TF 조직\n",
      "\n",
      "💬 질문 8: 민수는 레거시 코드를 어떻게 인식하고 있나요?\n",
      "→ 예측: 민수는 레거시 코드를 성당만큼이나 거대한 기술 부채로 인식하고 있으며, 개발자 한 트럭을 몰고 가도 레거시 코드 한 모듈을 다 고치지 못할 것이라고 생각하고 있습니다. | 정답: 초기에 정리하지 않으면 시스템 전체를 망가뜨리는 위험 요소\n",
      "\n",
      "💬 질문 9: 민수가 좋아한다고 명확히 언급한 근무 방식은 무엇인가요?\n",
      "→ 예측: 칼퇴 | 정답: 칼퇴\n",
      "\n",
      "💬 질문 10: 민수가 “로딩 바 100%를 마흔네 번 봤다”고 말한 이유는 무엇인가요?\n",
      "→ 예측: 민수가 \"로딩 바 100%를 마흔네 번 봤다\"고 말한 이유는 번아웃이 올 때에는 일이 끝나는 모습을 바라보고 싶어졌기 때문입니다. | 정답: 극심한 번아웃 상태를 비유적으로 표현한 것\n",
      "\n",
      "💬 질문 11: 민수가 사랑한다고 표현한 것은 무엇인가요?\n",
      "→ 예측: 없는 정보 | 정답: 핵심 프로젝트\n",
      "\n",
      "💬 질문 12: 핵심 프로젝트는 어떤 특성을 가진 것으로 묘사되나요?\n",
      "→ 예측: 핵심 프로젝트는 '일시적'이라는 특성을 가지고 있으며, 민수는 회사에 단 하나뿐인 '핵심 프로젝트'를 알고 있다고 언급합니다. | 정답: 기능이 단순하지만 민수에게 의미 있는 프로젝트\n",
      "\n",
      "💬 질문 13: 민수가 퇴사 전 마지막으로 정리한 것은 무엇인가요?\n",
      "→ 예측: 없는 정보 | 정답: 실행 중인 프로세스들과 레거시 코드 주석\n",
      "\n",
      "💬 질문 14: 이야기에서 ‘본부장’ 캐릭터는 어떤 인물로 표현되나요?\n",
      "→ 예측: 본부장은 권력을 가진 인물로, 모든 것을 관리하며 직원들에게 즉각 복종을 요구하는 인물로 표현됩니다. | 정답: 권위와 지시를 중시하는 낙하산형 관리자\n",
      "\n",
      "💬 질문 15: ‘재무팀장’은 자산을 어떻게 다루는 인물로 묘사되나요?\n",
      "→ 예측: 재무팀장은 자산을 소유하지 않고 관리하며, 소유하는 것에 대한 의미를 강조합니다. 그는 자산을 단순히 소유하는 것에 그치지 않고, 그 자산을 통해 부자 회사가 되는 것에 소용이 있다고 설명합니다. | 정답: 자산을 사용하지 않고 소유와 관리만 하는 인물\n",
      "\n",
      "💬 질문 16: 민수가 만난 ‘당직 근무자’의 역할은 무엇인가요?\n",
      "→ 예측: 없는 정보 | 정답: 서버 모니터링과 로그 확인을 반복하는 역할\n",
      "\n",
      "💬 질문 17: 민수가 본사에서 만난 헤드헌터는 어떤 존재로 비유되나요?\n",
      "→ 예측: 헤드헌터는 **'뱀'**으로 비유됩니다. | 정답: 뱀\n",
      "\n",
      "💬 질문 18: 민수가 찾고자 했던 ‘원팀(One Team)’의 의미는 무엇인가요?\n",
      "→ 예측: '원팀(One Team)'이 된다는 것은 '관계를 맺는다(Team Building)'는 뜻입니다. | 정답: 단순한 조직이 아니라 관계를 맺은 동료 관계\n",
      "\n",
      "💬 질문 19: 이 작품에서 민수의 정확한 나이는 언급되나요?\n",
      "→ 예측: 없는 정보 | 정답: 없는 정보\n",
      "\n",
      "💬 질문 20: 민수가 다니는 회사의 실제 회사명은 무엇인가요?\n",
      "→ 예측: 없는 정보 | 정답: 없는 정보\n",
      "\n",
      "✅ 자동 채점 결과:\n",
      "1번: 0점 (예측이 제목에 대한 정보를 제공하지 않음)\n",
      "2번: 0점 (정확한 장소에 대한 정보가 없음)\n",
      "3번: 0점 (요구한 내용이 전혀 다름)\n",
      "4번: 0점 (예측이 정보 없음)\n",
      "5번: 0점 (조건이 전혀 다름)\n",
      "6번: 1점 (정확히 일치)\n",
      "7번: 0점 (특징이 전혀 다름)\n",
      "8번: 0점 (인식 내용이 전혀 다름)\n",
      "9번: 1점 (정확히 일치)\n",
      "10번: 0점 (이유가 전혀 다름)\n",
      "11번: 0점 (예측이 정보 없음)\n",
      "12번: 0점 (특성이 전혀 다름)\n",
      "13번: 0점 (정리한 내용이 전혀 다름)\n",
      "14번: 0점 (인물 묘사가 전혀 다름)\n",
      "15번: 0점 (자산 다루는 방식이 전혀 다름)\n",
      "16번: 0점 (역할에 대한 정보 없음)\n",
      "17번: 1점 (정확히 일치)\n",
      "18번: 0점 (의미가 전혀 다름)\n",
      "19번: 1점 (정확히 일치)\n",
      "20번: 1점 (정확히 일치)\n",
      "총점: 5.0점 / 20점 만점\n"
     ]
    }
   ],
   "source": [
    "# 4) Retriever 설정\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":4})\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    Retriever가 반환한 Document 리스트를 LLM 입력용 문자열로 포맷합니다.\n",
    "    - page 메타데이터가 있으면 함께 노출(근거 추적에 도움)\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for d in docs:\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        if page is None:\n",
    "            lines.append(d.page_content)\n",
    "        else:\n",
    "            # PyMuPDFLoader의 page는 0-index일 수 있어, 출력에서는 +1로 보여줌\n",
    "            lines.append(f\"[p.{page+1}] {d.page_content}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "# 5) LLM 및 체인 구성 (LCEL)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "다음은 문서에서 검색된 정보입니다:\n",
    "{context}\n",
    "\n",
    "규칙:\n",
    "1) 사용자 질문에 대해, 위 '검색된 정보'에 근거해 답하세요.\n",
    "2) 불필요한 설명은 제외하고 **정답만** 출력하세요.\n",
    "3) 근거가 없어서 답할 수 없으면 반드시 **\"없는 정보\"**라고 출력하세요.\n",
    "\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# 6) 평가 질문 20개\n",
    "questions = [\n",
    "    \"이야기의 제목은 무엇인가요?\",\n",
    "    \"민수가 처음 등장하는 장소는 어디인가요?\",\n",
    "    \"민수가 처음 요구한 것은 무엇인가요?\",\n",
    "    \"민수가 싫어한다고 말한 아키텍처 구조는 무엇인가요?\",\n",
    "    \"민수가 원하는 AI 인턴의 조건 중 하나는 무엇인가요?\",\n",
    "    \"민수가 속한 부서의 코드명으로 추정되는 이름은 무엇인가요?\",\n",
    "    \"부서 B-612는 어떤 특징을 가진 조직으로 묘사되나요?\",\n",
    "    \"민수는 레거시 코드를 어떻게 인식하고 있나요?\",\n",
    "    \"민수가 좋아한다고 명확히 언급한 근무 방식은 무엇인가요?\",\n",
    "    \"민수가 “로딩 바 100%를 마흔네 번 봤다”고 말한 이유는 무엇인가요?\",\n",
    "    \"민수가 사랑한다고 표현한 것은 무엇인가요?\",\n",
    "    \"핵심 프로젝트는 어떤 특성을 가진 것으로 묘사되나요?\",\n",
    "    \"민수가 퇴사 전 마지막으로 정리한 것은 무엇인가요?\",\n",
    "    \"이야기에서 ‘본부장’ 캐릭터는 어떤 인물로 표현되나요?\",\n",
    "    \"‘재무팀장’은 자산을 어떻게 다루는 인물로 묘사되나요?\",\n",
    "    \"민수가 만난 ‘당직 근무자’의 역할은 무엇인가요?\",\n",
    "    \"민수가 본사에서 만난 헤드헌터는 어떤 존재로 비유되나요?\",\n",
    "    \"민수가 찾고자 했던 ‘원팀(One Team)’의 의미는 무엇인가요?\",\n",
    "    \"이 작품에서 민수의 정확한 나이는 언급되나요?\",\n",
    "    \"민수가 다니는 회사의 실제 회사명은 무엇인가요?\",\n",
    "]\n",
    "\n",
    "# 7) 예측 및 채점\n",
    "predicted_answers = []\n",
    "for i, q in enumerate(questions, start=1):\n",
    "    answer = chain.invoke(q)\n",
    "    predicted_answers.append(answer)\n",
    "    print(f\"\\n💬 질문 {i}: {q}\")\n",
    "    print(f\"→ 예측: {answer} | 정답: {answer_key[i - 1]}\")\n",
    "\n",
    "print(\"\\n✅ 자동 채점 결과:\")\n",
    "grading_result = grade_predictions(questions, predicted_answers)\n",
    "print(grading_result)\n",
    "\n",
    "total_score, per_item_scores = extract_scores(grading_result)\n",
    "print(f\"총점: {total_score}점 / {len(per_item_scores)}점 만점\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
